{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ddc83f2-c30e-4fd7-be52-14ad360f9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a1d05-cecf-4d54-b550-dbb1f0cfbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_positive_anchor_images(file_path, image_name, image_type, n_samples=300, create_new=False, to_log=False):\n",
    "    \"\"\"OpenCV real time positive and anchor images reciever.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: str\n",
    "        Path to the file positive and anchor images will be stored.\n",
    "    image_name: str\n",
    "        Nickname of the person, which image will be captured.\n",
    "    image_type: 'positive' | 'anchor'\n",
    "        Image type whether positive or anchor.\n",
    "    n_samples: int\n",
    "        The amount of images should be captured.\n",
    "    create_new: bool\n",
    "        Whether to truncate existing folders with positive and anchor images or not.\n",
    "    to_log: bool\n",
    "        Whether or not to show up the counter of anchor and positive images made from the beginning of the session.\n",
    "    \"\"\"\n",
    "    file_io      = None\n",
    "    counter      = 0\n",
    "    temp_storage = 'temp_storage'\n",
    "    \n",
    "    file_io = h5py.File(file_path, 'a')\n",
    "    if create_new:\n",
    "        try:\n",
    "            if image_type == 'anchor':\n",
    "                del file_io['anchor']\n",
    "            else:\n",
    "                del file_io['positive']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    os.mkdir(temp_storage)\n",
    "    if image_type == 'anchor':\n",
    "        file_io.create_group('anchor')\n",
    "    else:\n",
    "        file_io.create_group('positive')\n",
    "    \n",
    "    cam = cv2.VideoCapture(cv2.CAP_V4L2)\n",
    "    uid = uuid.uuid1()\n",
    "    try:\n",
    "        while cam.isOpened():\n",
    "            _, frame = cam.read()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = frame[120:370, 200:450, :]\n",
    "\n",
    "            cv2.imshow('Verification', frame)\n",
    "            \n",
    "            if image_type == 'anchor':\n",
    "                path = os.path.join(temp_storage, f'{(image_name + \"-\" + str(uid))}.jpg')\n",
    "                cv2.imwrite(path, frame)\n",
    "\n",
    "                uid = uuid.uuid1()\n",
    "                counter += 1\n",
    "                if to_log:\n",
    "                    print(f'#{counter} anchor added!')\n",
    "                if counter > n_samples-1:\n",
    "                    break\n",
    "            else:\n",
    "                path = os.path.join(temp_storage, f'{(image_name + \"-\" + str(uid))}.jpg')\n",
    "                cv2.imwrite(path, frame)\n",
    "\n",
    "                uid = uuid.uuid1()\n",
    "                counter += 1\n",
    "                if to_log:\n",
    "                    print(f'#{counter} positive added!')\n",
    "                if counter > n_samples-1:\n",
    "                    break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        for image in os.listdir(temp_storage):\n",
    "            byte_img = tf.io.read_file(os.path.join(temp_storage, image))\n",
    "            path = os.path.join(image_type, image[:-4])\n",
    "            img = tf.io.decode_jpeg(byte_img).numpy()\n",
    "            file_io.create_dataset(path, (250, 250, 3), chunks=True)\n",
    "            file_io[path][:, :, :] = img\n",
    "        file_io.close()\n",
    "        shutil.rmtree(temp_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8347ec38-0806-4fde-90b3-b3886f9906a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \"\"\"Data workflow for downloading, moving and getting data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    log_prefix: str\n",
    "        Prefix for log functions and decorators.\n",
    "    url: str\n",
    "        The url source from which the file will be downloaded.\n",
    "    file_name: str\n",
    "        Name of the file which will be downloaded from the url.\n",
    "    to_log: bool\n",
    "        Whether to turn on logging or not.\n",
    "    \"\"\"\n",
    "    log_prefix = 'DataLoader::'\n",
    "    def __init__(self, url, to_log=False):\n",
    "        self.url       = url\n",
    "        self.file_name = self.url.split('/')[-1]\n",
    "        self.to_log    = to_log\n",
    "\n",
    "        self.__downloaded_file = None\n",
    "    \n",
    "    def __download_tar_file(self):\n",
    "        \"\"\"Downloads a tar file from the specified url.\n",
    "        \"\"\"\n",
    "        response = requests.get(self.url, stream=True)\n",
    "        self.__downloaded_file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "        \n",
    "    def __download_file(self):\n",
    "        \"\"\"Downloads a file from the specified url.\n",
    "        \"\"\"\n",
    "        assert requests.get(self.url).ok, \"Established url is not reachable!\"\n",
    "        \n",
    "        extension = self.file_name.split('.')[-1]\n",
    "\n",
    "        if extension in ['tgz', 'tbz', 'txz']:\n",
    "            time_logger(log_name=f'{self.log_prefix}download_tar_file', log_on=self.to_log)\\\n",
    "            (self.__download_tar_file)()\n",
    "        else:\n",
    "            raise Exception('Download is not performed as this format is not maintained!')\n",
    "\n",
    "    def __extract_tgz_file(self):\n",
    "        \"\"\"Extracts downloaded tgz file.\n",
    "        \"\"\"\n",
    "        assert self.file_name.endswith('.tgz'), \"Downloaded dataset is not tgz format!\"\n",
    "\n",
    "        self.__downloaded_file.extractall(path='.')\n",
    "        self.__downloaded_file = None\n",
    "  \n",
    "    def __extract_file(self):\n",
    "        \"\"\"Extracts downloaded file.\n",
    "        \"\"\"\n",
    "        assert self.__downloaded_file is not None, \"Dataset is not downloaded yet!\"\n",
    "        \n",
    "        extension = self.file_name.split('.')[-1]\n",
    "\n",
    "        if extension == 'tgz':\n",
    "            time_logger(log_name=f'{self.log_prefix}extract_tgz_file', log_on=self.to_log)\\\n",
    "            (self.__extract_tgz_file)()\n",
    "        else:\n",
    "            raise Exception('Extraction is not performed as this format is not maintained!')\n",
    "    \n",
    "    def __to_hdf5(self, h5file_path, data_path, group, quantity_of_images, data_path_type='standard'):\n",
    "        \"\"\"Moves data to h5 file.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        h5file_path: str\n",
    "            File path with the .h5 extension, in which images will be moved.\n",
    "        data_path: str\n",
    "            Path to data folder with images or folders (classnames) with images.\n",
    "        group: str\n",
    "            Group (folder) name in the .h5, in which images (datasets) will be stored.\n",
    "        quantity_of_images: int\n",
    "            The amount of images that will be download to the .h5 file.\n",
    "        data_path_type: 'standard' | 'all_in_one'\n",
    "            'standard' gains the 'data_path', which consists of folder (classnames) with images.\n",
    "            'all_in_one' gain the 'data_path', which consists of images only.\n",
    "        \"\"\"\n",
    "        assert h5file_path.endswith('h5'), \"Don't forget to add .h5 to file name!\"\n",
    "        \n",
    "        with h5py.File(h5file_path, 'w', driver='core', block_size=1024) as f:\n",
    "            f.create_group(group)\n",
    "            \n",
    "            if data_path_type == 'standard':\n",
    "                root = os.listdir(data_path)\n",
    "                np.random.shuffle(root)\n",
    "                for directory in root[:quantity_of_images]:\n",
    "                    image = os.listdir(os.path.join(data_path, directory))[0]\n",
    "                    image_path = os.path.join(group, image.split('.')[0])\n",
    "                    f.create_dataset(image_path, (250, 250, 3), dtype='f', chunks=True)\n",
    "                    byte_img = tf.io.read_file(os.path.join(data_path, directory, image))\n",
    "                    img = tf.io.decode_jpeg(byte_img).numpy()\n",
    "                    f[image_path][:, :, :] = img\n",
    "            elif data_path_type == 'all_in_one':\n",
    "                root = os.listdir(data_path)\n",
    "                np.random.shuffle(root)\n",
    "                for image in root[:quantity_of_images]:\n",
    "                    image_path = os.path.join(group, image.split('.')[0])\n",
    "                    f.create_dataset(image_path, (250, 250, 3), dtype='f', chunks=True)\n",
    "                    byte_img = tf.io.read_file(os.path.join(data_path, directory, image))\n",
    "                    img = tf.io.decode_jpeg(byte_img).numpy()\n",
    "                    f[image_path][:, :, :] = img\n",
    "\n",
    "    def __move_data(self, file_path, data_path, extension, **kwargs):\n",
    "        \"\"\"Moves data to another file/folder.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_name: str\n",
    "            File name, in which images will be moved.\n",
    "        data_path: str\n",
    "            Path to data folder with images or folders (classnames) with images.\n",
    "        extension: str\n",
    "            Extension of the file in which images will be stored, like 'hdf5'.\n",
    "        \"\"\"\n",
    "        if extension == 'hdf5':\n",
    "            assert kwargs.get('group') and \\\n",
    "                   kwargs.get('quantity_of_images'),\\\n",
    "            \"Group or/and quantity_of_images arguments haven't been set for hdf5. Set the arguments!\"\n",
    "            \n",
    "            time_logger(log_name=f'{self.log_prefix}to_hdf5', log_on=self.to_log)\\\n",
    "            (self.__to_hdf5)(file_path, data_path, **kwargs)\n",
    "        else:\n",
    "            raise Exception('Move is not performed as this format is not maintained!')\n",
    "    \n",
    "    def __from_hdf5(self, h5file_path, mode, folder=None, img=None):\n",
    "        \"\"\"Gets data from the .h5 file.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        h5file_path: str\n",
    "            Path to the .h5 file to get data from.\n",
    "        mode: 'all' | 'dir' | 'img'\n",
    "            Specifies the type of get.\n",
    "            'all' get all datasets (images) from every group (folder).\n",
    "            'dir' get all datasets (images) from specified group (folder).\n",
    "            'img' get specified dataset (image) from the specified group (folder).\n",
    "        folder: str | None\n",
    "            If mode equals 'dir' the 'folder' argument is required. Specifies the group (folder),\n",
    "            from which all images will be obtained.\n",
    "        img: str | None\n",
    "            If mode equals 'img' the 'folder' and 'img' arguments are required. Specifies the dataset (image)\n",
    "            and group (folder) to get.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: list\n",
    "            Returns gathered data form the .h5 file.\n",
    "        \"\"\"\n",
    "        assert h5file_path.endswith('h5'), \"Don't forget to add .h5 to file name!\"\n",
    "        if mode == 'dir' and folder is None:\n",
    "            raise Exception('In \\'dir\\' mode you must specify folder argument!')\n",
    "        if mode == 'img' and (folder is None or img is None):\n",
    "            raise Exception('In \\'img\\' mode you must specify folder and img arguments!')\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        with h5py.File(h5file_path, 'r') as f:\n",
    "            if mode == 'all':\n",
    "                for folder in f.keys():\n",
    "                    images = [image_name for image_name in f[folder].keys()]\n",
    "                    for image in images:\n",
    "                        data.append(np.array(f[folder + '/' + image]))\n",
    "            elif mode == 'dir':\n",
    "                images = [image_name for image_name in f[folder].keys()]\n",
    "                for image in images:\n",
    "                    data.append(np.array(f[folder + '/' + image]))\n",
    "            elif mode == 'img':\n",
    "                data.append(np.array(f[folder + '/' + img]))\n",
    "            else:\n",
    "                raise Exception('No such mode in hdf5! Choose followings: \\'all\\', \\'dir\\', \\'img\\'')\n",
    "                \n",
    "        return data\n",
    "    \n",
    "    def __get_data(self, file_path, extension, mode, **kwargs):\n",
    "        \"\"\"Gets data from a file.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path to the file to get data from.\n",
    "        extensions: str\n",
    "            Extension of the file in which images will be stored, like 'hdf5'.\n",
    "        mode: 'all' | 'dir' | 'img'\n",
    "            Specifies the type of get.\n",
    "            'all' get all images from every folder.\n",
    "            'dir' get all images from specified folder.\n",
    "            'img' get specified image from the specified folder.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: list\n",
    "            Returns gathered data from a file.\n",
    "        \"\"\"\n",
    "        assert os.path.exists(file_path), f\"File {file_path} doesn't exist!\"\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        if extension == 'hdf5':\n",
    "            data = self.__from_hdf5(file_path, mode, **kwargs)\n",
    "        else:\n",
    "            raise Exception('Get is not performed as this format is not maintained!')\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_all(self, file_path, extension):\n",
    "        \"\"\"Gets all data from a file.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path to the file to get data from.\n",
    "        extensions: str\n",
    "            Extension of the file in which images will be stored, like 'hdf5'.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: list\n",
    "            Returns all gathered data from a file.\n",
    "        \"\"\"\n",
    "        data = self.__get_data(file_path, extension, mode='all')\n",
    "        return data\n",
    "    \n",
    "    def get_by_dir(self, file_path, extension, **kwargs):\n",
    "        \"\"\"Gets data from a file by directory.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path to the file to get data from.\n",
    "        extensions: str\n",
    "            Extension of the file in which images will be stored, like 'hdf5'.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: list\n",
    "            Returns gathered data from a file by directory.\n",
    "        \"\"\"\n",
    "        data = self.__get_data(file_path, extension, mode='dir', **kwargs)\n",
    "        return data\n",
    "    \n",
    "    def get_by_image(self, file_path, extension, **kwargs):\n",
    "        \"\"\"Gets data from a file by image and directory.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Path to the file to get data from.\n",
    "        extensions: str\n",
    "            Extension of the file in which images will be stored, like 'hdf5'.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: list\n",
    "            Returns gathered data from a file by image and directory.\n",
    "        \"\"\"\n",
    "        data = self.__get_data(file_path, extension, mode='img', **kwargs)\n",
    "        return data\n",
    "\n",
    "    def load_file(self, to_download=True, to_extract=True, to_move=True, **kwargs):\n",
    "        \"\"\"Data loading workflow.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        to_download: bool\n",
    "            Whether to download file or not.\n",
    "        to_extract: bool\n",
    "            Whether to extract downloaded file or not.\n",
    "        to_move: ball\n",
    "            Whether to move downloaded file or not.\n",
    "        \"\"\"\n",
    "        if to_download:\n",
    "            self.__download_file()\n",
    "        if to_extract:\n",
    "            self.__extract_file()\n",
    "        if to_move:\n",
    "            assert kwargs.get('file_path') and \\\n",
    "                   kwargs.get('data_path') and \\\n",
    "                   kwargs.get('extension'),\\\n",
    "            \"file_name or data_path or extensions argument(-s) is not set. Set following arguments!\"\n",
    "            \n",
    "            self.__move_data(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d0fc1-72ea-49a7-8aaa-c3dde5c174e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor():\n",
    "    \"\"\"Data workflow for downloading, moving and getting data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    log_prefix: str\n",
    "        Prefix for log functions and decorators.\n",
    "    positive_data: list\n",
    "        Positive dataset to preprocess.\n",
    "    negative_data: list\n",
    "        Negative dataset to preprocess.\n",
    "    anchor_data: list\n",
    "        Anchor dataset to preprocess.\n",
    "    to_log: bool\n",
    "        Whether to turn on logging or not.\n",
    "    \"\"\"\n",
    "    log_prefix = 'DataPreprocessor::'\n",
    "    def __init__(self, positive_data, negative_data, anchor_data, to_log=False):\n",
    "        assert len(positive_data) == len(negative_data) == len(anchor_data), \\\n",
    "        \"Shapes of all positive, negative and anchor datasets must coincide!\"\n",
    "        \n",
    "        self.positive_data = positive_data\n",
    "        self.negative_data = negative_data\n",
    "        self.anchor_data   = anchor_data\n",
    "        self.len_data      = len(positive_data)\n",
    "        self.to_log        = to_log\n",
    "        \n",
    "        self.__anchor_positive_data = None\n",
    "        self.__anchor_negative_data = None\n",
    "        self.__preprocessed_data    = None\n",
    "        self.__train_data           = None\n",
    "        self.__test_data            = None\n",
    "    \n",
    "    def __zip_data(self):\n",
    "        \"\"\"Zips two data and convert it to tf.data.Dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.__anchor_positive_data = tf.data.Dataset.zip((\n",
    "            tf.data.Dataset.from_tensors(self.anchor_data),\n",
    "            tf.data.Dataset.from_tensors(self.positive_data),\n",
    "            tf.data.Dataset.from_tensor_slices(tf.ones(self.len_data)),\n",
    "        ))\n",
    "        \n",
    "        self.__anchor_negative_data = tf.data.Dataset.zip((\n",
    "            tf.data.Dataset.from_tensors(self.anchor_data),\n",
    "            tf.data.Dataset.from_tensors(self.negative_data),\n",
    "            tf.data.Dataset.from_tensor_slices(tf.zeros(self.len_data)),\n",
    "        ))\n",
    "        print(self.__anchor_positive_data)\n",
    "        print(self.__anchor_negative_data)\n",
    "    \n",
    "    def __merge_data(self, shuffle=True):\n",
    "        \"\"\"Merges two data into one dataset.\n",
    "        \n",
    "        Caches tensors in RAM.\n",
    "        Shuffles data in the dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        shuffle: bool\n",
    "            Whether or not shuffle merged data.\n",
    "        \"\"\"\n",
    "        assert self.__anchor_positive_data is not None and \\\n",
    "               self.__anchor_negative_data is not None, \\\n",
    "        \"Initialized data should be zipped before merge!\"\n",
    "        \n",
    "        self.__preprocessed_data = self.__anchor_positive_data.concatenate(self.__anchor_negative_data)\n",
    "        print(self.__preprocessed_data)\n",
    "        self.__preprocessed_data.cache()\n",
    "        \n",
    "        if shuffle:\n",
    "            self.__preprocessed_data.shuffle(buffer_size=self.len_data * 2)\n",
    "    \n",
    "    def __augmentate_data(\n",
    "        self,\n",
    "        brightness=0,\n",
    "        contrast=None,\n",
    "        flip_left_right=False,\n",
    "        jpeg_quality=None,\n",
    "        saturation=None,\n",
    "    ):\n",
    "        \"\"\"Perform data augmentation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        brightness: float\n",
    "            Brightness.\n",
    "        contrast: list[float, float] | tuple(float, float)\n",
    "            Lower and upper bounds for the random contrast factor. \n",
    "        flip_left_right: bool\n",
    "            Whether to flip image verticaly or not.\n",
    "        jpeg_quality: list[float, float] | tuple(float, float)\n",
    "            Minimum and maximum jpeg encodings quality to use. \n",
    "        saturation: list[float, float] | tuple(float, float)\n",
    "            Lower and upper bounds for the random saturation factor. \n",
    "        \"\"\"\n",
    "        positive_buff = []\n",
    "        negative_buff = []\n",
    "        anchor_buff   = []\n",
    "        seed          = (42, 24)\n",
    "        \n",
    "        for positive_image, negative_image, anchor_image in zip(self.positive_data, self.negative_data, self.anchor_data):\n",
    "            positive_image = tf.image.stateless_random_brightness(positive_image, max_delta=brightness, seed=seed)\n",
    "            positive_image = tf.image.stateless_random_contrast(positive_image, lower=contrast[0], upper=contrast[1], seed=seed)\n",
    "            positive_image = tf.image.stateless_random_flip_left_right(positive_image, seed=seed)\n",
    "            positive_image = tf.image.stateless_random_jpeg_quality(positive_image, min_jpeg_quality=jpeg_quality[0], max_jpeg_quality=jpeg_quality[1], seed=seed)\n",
    "            positive_image = tf.image.stateless_random_saturation(positive_image, lower=saturation[0], upper=saturation[1], seed=seed)\n",
    "            positive_image = tf.image.resize(positive_image, IMAGE_SIZE)\n",
    "            positive_image = positive_image / 255.0\n",
    "            \n",
    "            negative_image = tf.image.stateless_random_brightness(negative_image, max_delta=brightness, seed=seed)\n",
    "            negative_image = tf.image.stateless_random_contrast(negative_image, lower=contrast[0], upper=contrast[1], seed=seed)\n",
    "            negative_image = tf.image.stateless_random_flip_left_right(negative_image, seed=seed)\n",
    "            negative_image = tf.image.stateless_random_jpeg_quality(negative_image, min_jpeg_quality=jpeg_quality[0], max_jpeg_quality=jpeg_quality[1], seed=seed)\n",
    "            negative_image = tf.image.stateless_random_saturation(negative_image, lower=saturation[0], upper=saturation[1], seed=seed)\n",
    "            negative_image = tf.image.resize(negative_image, IMAGE_SIZE)\n",
    "            negative_image = negative_image / 255.0\n",
    "            \n",
    "            anchor_image = tf.image.stateless_random_brightness(anchor_image, max_delta=brightness, seed=seed)\n",
    "            anchor_image = tf.image.stateless_random_contrast(anchor_image, lower=contrast[0], upper=contrast[1], seed=seed)\n",
    "            anchor_image = tf.image.stateless_random_flip_left_right(anchor_image, seed=seed)\n",
    "            anchor_image = tf.image.stateless_random_jpeg_quality(anchor_image, min_jpeg_quality=jpeg_quality[0], max_jpeg_quality=jpeg_quality[1], seed=seed)\n",
    "            anchor_image = tf.image.stateless_random_saturation(anchor_image, lower=saturation[0], upper=saturation[1], seed=seed)\n",
    "            anchor_image = tf.image.resize(anchor_image, IMAGE_SIZE)\n",
    "            anchor_image = anchor_image / 255.0\n",
    "            \n",
    "            positive_buff.append(positive_image)\n",
    "            negative_buff.append(negative_image)\n",
    "            anchor_buff.append(anchor_image)\n",
    "        \n",
    "        self.positive_data = positive_buff.copy()\n",
    "        self.negative_data = negative_buff.copy()\n",
    "        self.anchor_data   = anchor_buff.copy()\n",
    "    \n",
    "    def __train_test_split(self, test_size=0.2):\n",
    "        \"\"\"Performs data split on train and test datasets.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        test_size: float\n",
    "            The fraction of test size in respect of inputted data.\n",
    "        \"\"\"\n",
    "        assert self.__preprocessed_data is not None, \"The dataset must be merged before the 'train_test_split'!\"\n",
    "        \n",
    "        self.__train_data = self.__preprocessed_data.take(round(self.len_data * 2 * (1 - test_size)))\n",
    "        self.__train_data = self.__train_data.batch(16)\n",
    "        self.__train_data = self.__train_data.prefetch(8)\n",
    "        \n",
    "        self.__test_data = self.__preprocessed_data.skip(round(self.len_data * 2 * (1 - test_size)))\n",
    "        self.__test_data = self.__test_data.take(round(self.len_data * 2 * test_size))\n",
    "        self.__test_data = self.__test_data.batch(16)\n",
    "        self.__test_data = self.__test_data.prefetch(8)\n",
    "    \n",
    "    def __preprocess_data(self, shuffle, test_size=0.2, **kwargs):\n",
    "        \"\"\"Preprocess data.\n",
    "        \n",
    "        Resizes the image to 105x105 pixels.\n",
    "        Scales pixels of the image between 0 and 1.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        shuffle: bool\n",
    "            Whether or not to shuffle dataset.\n",
    "        test_size: float\n",
    "            The fraction of test size in respect of inputted data.\n",
    "        \"\"\"\n",
    "        \n",
    "        time_logger(log_name=f'{self.log_prefix}augmentate_data', log_on=self.to_log)\\\n",
    "        (self.__augmentate_data)(**kwargs)\n",
    "        \n",
    "        time_logger(log_name=f'{self.log_prefix}zip_data', log_on=self.to_log)\\\n",
    "        (self.__zip_data)()\n",
    "        \n",
    "        time_logger(log_name=f'{self.log_prefix}merge_data', log_on=self.to_log)\\\n",
    "        (self.__merge_data)(shuffle=shuffle)\n",
    "        \n",
    "        time_logger(log_name=f'{self.log_prefix}train_test_split', log_on=self.to_log)\\\n",
    "        (self.__train_test_split)(test_size)\n",
    "        \n",
    "    def perform_preprocessing(\n",
    "        self,\n",
    "        brightness=0,\n",
    "        contrast=None,\n",
    "        flip_left_right=False,\n",
    "        jpeg_quality=None,\n",
    "        saturation=None,\n",
    "        shuffle=True\n",
    "    ):\n",
    "        \"\"\"Performs data preprocessing.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        brightness: float\n",
    "            Brightness.\n",
    "        contrast: list[float, float] | tuple(float, float)\n",
    "            Lower and upper bounds for the random contrast factor. \n",
    "        flip_left_right: bool\n",
    "            Whether to flip image verticaly or not.\n",
    "        jpeg_quality: list[float, float] | tuple(float, float)\n",
    "            Minimum and maximum jpeg encodings quality to use. \n",
    "        saturation: list[float, float] | tuple(float, float)\n",
    "            Lower and upper bounds for the random saturation factor. \n",
    "        shuffle: bool\n",
    "            Whether shuffle or not preprocessed data.\n",
    "        \"\"\"\n",
    "        time_logger(log_name=f'{self.log_prefix}process_data', log_on=self.to_log)\\\n",
    "        (self.__preprocess_data)(\n",
    "            shuffle,\n",
    "            brightness=0.02,\n",
    "            contrast=(0.6, 1),\n",
    "            flip_left_right=True,\n",
    "            jpeg_quality=(90, 100),\n",
    "            saturation=(0.9, 1),\n",
    "        )\n",
    "    \n",
    "    def get_train_test_data(self):\n",
    "        \"\"\"Get preprocessed train test data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        train_data: tf.data.Dataset\n",
    "            Train data split.\n",
    "        test_data: tf.data.Dataset\n",
    "            Test data split.\n",
    "        \"\"\"\n",
    "        assert self.__train_data is not None and \\\n",
    "               self.__test_data is not None, \\\n",
    "        \"Run train_test_split before requesting train test data!\"\n",
    "        \n",
    "        return (self.__train_data, self.__test_data)\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Get preprocessed or not data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data: list | tf.data.Dataset\n",
    "            Whether preprocessed or not data.\n",
    "        \"\"\"\n",
    "        if self.__preprocessed_data is not None:\n",
    "            return self.__preprocessed_data\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e275a-f43a-4ae8-a85a-a9800852c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceL1(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_embedding, valid_embedding):\n",
    "        return tf.math.abs(input_embedding - valid_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b542b-eb6b-4e08-9fb0-a38f0b6a49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNN(Model):\n",
    "    \"\"\"CNN Siamese model for face recognition.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_        = Input(shape=(*IMAGE_SIZE, 3), name='input')\n",
    "        self.conv2d_1      = Conv2D(filters=64, kernel_size=(10, 10), activation='relu')\n",
    "        self.max_pooling_1 = MaxPool2D(pool_size=(2, 2), padding='same')\n",
    "        self.conv2d_2      = Conv2D(filters=128, kernel_size=(7, 7), activation='relu')\n",
    "        self.max_pooling_2 = MaxPool2D(pool_size=(2, 2), padding='same')\n",
    "        self.conv2d_3      = Conv2D(filters=128, kernel_size=(4, 4), activation='relu')\n",
    "        self.max_pooling_3 = MaxPool2D(pool_size=(2, 2), padding='same')\n",
    "        self.conv2d_4      = Conv2D(filters=256, kernel_size=(4, 4), activation='relu')\n",
    "        self.flatten_      = Flatten()\n",
    "        self.dense_        = Dense(units=4096, activation='sigmoid')\n",
    "        \n",
    "        self.own_embedding = None\n",
    "    \n",
    "    def make_embedding(self, name=''):\n",
    "        \"\"\"Embeds pipeline for a pair of images.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        name: str\n",
    "            Name of the embedded pipeline.\n",
    "        \"\"\"\n",
    "        x = self.conv2d_1(self.input_)\n",
    "        x = self.max_pooling_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.flatten_(x)\n",
    "        x = self.dense_(x)\n",
    "        \n",
    "        self.own_embedding = Model(inputs=self.input_, outputs=x, name=name)\n",
    "    \n",
    "    def call(self, other):\n",
    "        assert self.own_embedding is not None, f\"{self.__class__} must create own embedding through 'make_embedding' to create model!\"\n",
    "        assert other.own_embedding is not None, f\"{other.__class__} must create own embedding through 'make_embedding' to create model!\"\n",
    "        \n",
    "        real_input  = Input(name='real_input', shape=IMAGE_SIZE)\n",
    "        valid_input = Input(name='valid_input', shape=IMAGE_SIZE)\n",
    "        distance_l1 = DistanceL1()\n",
    "        print(self.own_embedding)\n",
    "        distance_l1 = distance_l1(self.own_embedding, other.own_embedding)\n",
    "        \n",
    "        model = Dense(units=1, activation='sigmoid')(distance_l1)\n",
    "        \n",
    "        return Model(inputs=[real_input, valid_input], outputs=model, name='SiameseNN')\n",
    "    \n",
    "    def get_instance(self):\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
