{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1666290833946,
     "user": {
      "displayName": "Dima Cho",
      "userId": "13241364511832483273"
     },
     "user_tz": -180
    },
    "id": "KKXUoibLXGEU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import uuid\n",
    "import h5py\n",
    "import time\n",
    "import tqdm\n",
    "import shutil\n",
    "import pathlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Layer\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "del gpu, gpus\n",
    "\n",
    "matplotlib.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEKzZqlZf4DP"
   },
   "source": [
    "## __Константы__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666294291534,
     "user": {
      "displayName": "Dima Cho",
      "userId": "13241364511832483273"
     },
     "user_tz": -180
    },
    "id": "AfDehjidfv08"
   },
   "outputs": [],
   "source": [
    "POSITIVE_DATA_PATH = pathlib.Path('positive')\n",
    "NEGATIVE_DATA_PATH = pathlib.Path('negative')\n",
    "ANCHOR_DATA_PATH   = pathlib.Path('anchor')\n",
    "\n",
    "IMAGE_SIZE         = (105, 105)\n",
    "BATCH_SIZE         = 32\n",
    "AUTOTUNE           = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "FACE_DETECTOR      = cv2.dnn.readNetFromCaffe(\n",
    "    'cascades/deploy.prototxt.txt', \n",
    "    'cascades/res10_300x300_ssd_iter_140000.caffemodel'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geoOpGnvslqA",
    "tags": []
   },
   "source": [
    "## __API__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Bo01bTHfZtN"
   },
   "source": [
    "## **Содержание**\n",
    "\n",
    "#### 1. **[Загрузка данных](#download)**\n",
    "#### 2. **[Обработка данных](#process)**\n",
    "#### 3. **[Построение модели](#build-it)**\n",
    "#### 4. **[Обучение модели](#teach-it)**\n",
    "#### 5. **[Валидация модели](#validate)**\n",
    "#### 6. **[Выгрузка модели](#upload)**\n",
    "#### 7. **[Проверка на реальном примере](#real-time)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qG3Mfgzf4LW"
   },
   "source": [
    "<a name=\"download\"></a>\n",
    "#### 1. **Загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Data workflow for downloading, moving and getting lfw and external data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    url: str\n",
    "        The url source from which the file will be downloaded.\n",
    "    storage_file: str\n",
    "        Name of the file in which will data be stored.\n",
    "    dataset_path: str\n",
    "        Path to the donwloaded lfw dataset.\n",
    "    \"\"\"\n",
    "    url          = 'http://vis-www.cs.umass.edu/lfw/lfw.tgz'\n",
    "    storage_file = 'lfw.h5'\n",
    "    \n",
    "    def __init__(self, url: str=None, storage_file: str=None) -> None:\n",
    "        self.url           = url if url else self.url\n",
    "        self.storage_file  = storage_file if storage_file else self.storage_file\n",
    "        self._dataset_path = None\n",
    "    \n",
    "    @property\n",
    "    def dataset_path(self) -> str:\n",
    "        \"\"\"Gets dataset_path.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str: Path to the donwloaded lfw dataset.\n",
    "        \"\"\"\n",
    "        return self._dataset_path\n",
    "    \n",
    "    @dataset_path.setter\n",
    "    def dataset_path(self, dataset_path: str) -> None:\n",
    "        \"\"\"Sets dataset_path, if required.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        dataset_path: str\n",
    "            Path to a dataset.\n",
    "        \"\"\"\n",
    "        self._dataset_path = dataset_path\n",
    "    \n",
    "    def download_lfw_dataset(self) -> (str, bool):\n",
    "        \"\"\"Download lfw dataset and sets dataset_path attribute.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str: status message of execution.\n",
    "        bool: status integer.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._dataset_path = tf.keras.utils.get_file(\n",
    "                fname='lfw',\n",
    "                origin=self.url, \n",
    "                untar=True\n",
    "            )\n",
    "            return 'LFW dataset was successfully downloaded!', 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            return e, 0\n",
    "    \n",
    "    def save(self, data: np.ndarray, dataset: str) -> (str, bool):\n",
    "        \"\"\"Saves specified data to the storage_file.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        data: np.ndarray\n",
    "            Single or collection of data which will be saved to the storage_file.\n",
    "        dataset: str\n",
    "            Dataset name.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str: status message of execution.\n",
    "        bool: status integer.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with h5py.File(self.storage_file, 'a', driver=None) as h5:\n",
    "                h5.create_dataset(\n",
    "                    dataset, shape=data.shape, dtype=h5py.h5t.IEEE_F16BE, data=data\n",
    "                )\n",
    "\n",
    "            return f'Data was successfully saved in {self.storage_file}!', 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            return e, 0\n",
    "    \n",
    "    def load(self, dataset: str) -> (np.ndarray | None, str, bool):\n",
    "        \"\"\"Loads specified data to the storage_file.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        dataset: str\n",
    "            Dataset name.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray | None: loaded data. If None was returned, an error occured.\n",
    "        str: status message of execution.\n",
    "        bool: status integer.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_file = h5py.File(self.storage_file, 'r', driver=None)\n",
    "            data = np.array(data_file[f'/{dataset}']).astype('float32')\n",
    "            data_file.close()\n",
    "            return data, f'Data was successfully loaded from {self.storage_file}', 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            return None, e, 0\n",
    "    \n",
    "    def delete(self) -> (str, bool):\n",
    "        \"\"\"Deletes the storage_file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str: status message of execution.\n",
    "        bool: status integer.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pathlib.Path(self.storage_file).unlink()\n",
    "            return f'{self.storage_file} was successfully deleted!', 1\n",
    "        except Exception as e:\n",
    "            return e, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_positive_negative_anchor_images_to_h5(\n",
    "    temp_anchor_path: str, temp_positive_path: str, temp_negative_path: str, data_loader: DataLoader\n",
    ") -> (str, bool):\n",
    "    \"\"\"Loads anchor, positive and negative images from temporary directories to h5 storage.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    temp_anchor_path: str\n",
    "        Temporary anchor directory of images that will be uploaded.\n",
    "    temp_positive_path: str\n",
    "        Temporary positive directory of images that will be uploaded.\n",
    "    temp_negative_path: str\n",
    "        Temporary negative directory of images that will be uploaded.\n",
    "    data_loader: DataLoader\n",
    "        The DataLoader object that will be used to upload data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        str: status message of execution.\n",
    "        bool: status integer.\n",
    "    \"\"\"\n",
    "    anchor_images_buffer   = []\n",
    "    positive_images_buffer = []\n",
    "    negative_images_buffer = []\n",
    "    \n",
    "    temp_anchor_path   = pathlib.Path(temp_anchor_path)\n",
    "    temp_positive_path = pathlib.Path(temp_positive_path)\n",
    "    temp_negative_path = pathlib.Path(temp_negative_path)\n",
    "    \n",
    "    try:\n",
    "        anchor_iter   = list(temp_anchor_path.glob('*.jpg'))\n",
    "        positive_iter = list(temp_positive_path.glob('*.jpg'))\n",
    "        negative_iter = list(temp_negative_path.glob('*/*'))\n",
    "        \n",
    "        np.random.shuffle(anchor_iter)\n",
    "        np.random.shuffle(positive_iter)\n",
    "        np.random.shuffle(negative_iter)\n",
    "\n",
    "        for anchor_image_path, positive_image_path in zip(anchor_iter, positive_iter):\n",
    "            anchor_image   = tf.keras.utils.load_img(anchor_image_path)\n",
    "            positive_image = tf.keras.utils.load_img(positive_image_path)\n",
    "\n",
    "            anchor_image   = tf.keras.utils.img_to_array(anchor_image)\n",
    "            positive_image = tf.keras.utils.img_to_array(positive_image)\n",
    "\n",
    "            anchor_images_buffer.append(anchor_image)\n",
    "            positive_images_buffer.append(positive_image)\n",
    "        \n",
    "        for i, negative_image_path in enumerate(negative_iter):\n",
    "            negative_image = tf.keras.utils.load_img(negative_image_path)\n",
    "            negative_image = tf.keras.utils.img_to_array(negative_image)\n",
    "            negative_images_buffer.append(negative_image)\n",
    "            if i == len(anchor_images_buffer) - 1:\n",
    "                break\n",
    "        \n",
    "        anchor_images_buffer   = np.array(anchor_images_buffer)\n",
    "        positive_images_buffer = np.array(positive_images_buffer)\n",
    "        negative_images_buffer = np.array(negative_images_buffer)\n",
    "        \n",
    "        data_loader.save(anchor_images_buffer, dataset=str(ANCHOR_DATA_PATH))\n",
    "        data_loader.save(positive_images_buffer, dataset=str(POSITIVE_DATA_PATH))\n",
    "        data_loader.save(negative_images_buffer, dataset=str(NEGATIVE_DATA_PATH))\n",
    "        \n",
    "        return \"Data is successfully saved to .h5!\", 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_faces(image: np.ndarray) -> (np.ndarray, int, int):\n",
    "    \"\"\"Apply faces detector to the image.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    image: np.ndarray\n",
    "        The image on which faces will be detected.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: ndarray of faces with specifications.\n",
    "    int: its width.\n",
    "    int: its height.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        cv2.resize(image, (300, 300)),\n",
    "        1,\n",
    "        (300, 300),\n",
    "        (104, 117, 123)\n",
    "    )\n",
    "    FACE_DETECTOR.setInput(blob)\n",
    "    faces = FACE_DETECTOR.forward()\n",
    "    faces_buff = [(confidence, \\\n",
    "                   int(x1 * width), int(y1 * height), \\\n",
    "                   int(x2 * width), int(y2 * height)) \\\n",
    "                 for _, _, confidence, x1, y1, x2, y2 \\\n",
    "                 in faces[0, 0] if confidence > 0.9]\n",
    "    \n",
    "    if faces_buff == []:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    _, x1, y1, x2, y2 = max(faces_buff, key=lambda x: x[0])\n",
    "    return x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def record_positive_anchor_images(\n",
    "    n_samples: int=300,\n",
    "    create_new: bool=False,\n",
    "    snap: bool=False,\n",
    "    prefix: str=None\n",
    ") -> (pathlib.Path, pathlib.Path):\n",
    "    \"\"\"OpenCV real time positive and anchor images receiver.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples: int, default=300\n",
    "        The amount of images will be taken. Both the anchor and the positive directories will have a half of them.\n",
    "    create_new: bool, default=False\n",
    "        Whether to truncate existing folders with positive and anchor images or not.\n",
    "    no_snap: bool, default=False\n",
    "        Whether to do snaps of the face or not.\n",
    "    prefix: str\n",
    "        Prefix of the images names. Required, if no_snap equals False\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pathlib.Path: temporary path to the anchor images directory.\n",
    "    pathlib.Path: temporary path to the positive images directory.\n",
    "    \"\"\"\n",
    "    if snap:\n",
    "        assert prefix is not None, \"Prefix is required while snap is True!\"\n",
    "    \n",
    "    data_dir     = pathlib.Path('data')\n",
    "    positive_dir = data_dir / 'positive'\n",
    "    anchor_dir   = data_dir / 'anchor'\n",
    "    metadata     = pathlib.Path('metadata')\n",
    "    \n",
    "    if create_new:\n",
    "        try:\n",
    "            shutil.rmtree(data_dir)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    \n",
    "    if not data_dir.exists():\n",
    "        data_dir.mkdir()\n",
    "    if not positive_dir.exists():\n",
    "        positive_dir.mkdir()\n",
    "    if not anchor_dir.exists():\n",
    "        anchor_dir.mkdir()\n",
    "    \n",
    "    rate = 0\n",
    "    if snap:\n",
    "        cam = cv2.VideoCapture(cv2.CAP_ANY)\n",
    "        uid = uuid.uuid1()\n",
    "        counter = 0\n",
    "\n",
    "        pbar = tqdm.tqdm(total=n_samples)\n",
    "        while cam.isOpened():\n",
    "            _, frame = cam.read()\n",
    "            frame = np.flip(frame, axis=1)\n",
    "            cv2.imshow('Recording in progress...', frame)\n",
    "            x1, y1, x2, y2 = get_faces(frame)\n",
    "            \n",
    "            if x1 and y1 and x2 and y2:\n",
    "                if not (rate % 3):\n",
    "                    frame = cv2.resize(frame[y1:y2, x1:x2], (250, 250))\n",
    "\n",
    "                    if counter < n_samples // 2:\n",
    "                        path = anchor_dir / f'{prefix}_{str(uid)}.jpg'\n",
    "                        cv2.imwrite(str(path), frame)\n",
    "                    else:\n",
    "                        path = positive_dir / f'{prefix}_{str(uid)}.jpg'\n",
    "                        cv2.imwrite(str(path), frame)\n",
    "\n",
    "                    uid = uuid.uuid1()\n",
    "                    counter += 1\n",
    "                    pbar.update(1)\n",
    "\n",
    "                rate += 1\n",
    "                    \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or counter == n_samples:\n",
    "                cam.release()\n",
    "                \n",
    "        with open(data_dir / metadata, 'a' if (data_dir / metadata).exists() else 'w') as f:\n",
    "            f.write(prefix + '\\n')\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return anchor_dir, positive_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LFW dataset was successfully downloaded!', 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "data_loader.download_lfw_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_negative_path = data_loader.dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_anchor_path, temp_positive_path = record_positive_anchor_images(200, create_new=False, snap=False, prefix='Cho_Hyun_Woo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lfw.h5 was successfully deleted!', 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Data is successfully saved to .h5!', 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_positive_negative_anchor_images_to_h5(\n",
    "    temp_anchor_path=temp_anchor_path,\n",
    "    temp_positive_path=temp_positive_path,\n",
    "    temp_negative_path=temp_negative_path,\n",
    "    data_loader=data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_anchor_path, temp_positive_path, temp_negative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images, _, _   = data_loader.load(str(ANCHOR_DATA_PATH))\n",
    "positive_images, _, _ = data_loader.load(str(POSITIVE_DATA_PATH))\n",
    "negative_images, _, _ = data_loader.load(str(NEGATIVE_DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(negative_images.shape[0]):\n",
    "    x1, y1, x2, y2 = get_faces(negative_images[i])\n",
    "    if x1 and y1 and x2 and y2:\n",
    "        if x1 >= 0 and y1 >= 0:\n",
    "            face = negative_images[i][y1:y2, x1:x2]\n",
    "        elif x1 < 0 and y1 >= 0:\n",
    "            face = negative_images[i][y1:y2, x2:x1]\n",
    "        elif y1 < 0 and x1 >= 0:\n",
    "            face = negative_images[i][y2:y1, x1:x2]\n",
    "        elif y1 < 0 and x1 < 0:\n",
    "            face = negative_images[i][y2:y1, x2:x1]\n",
    "        \n",
    "        negative_images[i] = cv2.resize(face, (250, 250))\n",
    "del i, x1, y1, x2, y2, face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNQ_pesWf4F8",
    "tags": []
   },
   "source": [
    "<a name=\"process\"></a>\n",
    "#### 2. **Обработка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"Data workflow for downloading, moving and getting data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    anchor_data: np.ndarray\n",
    "        Anchor images to preprocess.\n",
    "    positive_data: np.ndarray\n",
    "        Positive images to preprocess.\n",
    "    negative_data: np.ndarray\n",
    "        Negative images to preprocess.\n",
    "    \"\"\"\n",
    "    def __init__(self, anchor_images, positive_images, negative_images) -> None:\n",
    "        assert anchor_images.shape[0] == positive_images.shape[0] == negative_images.shape[0], \\\n",
    "        \"Shapes of all positive, negative and anchor datasets must coincide!\"\n",
    "        \n",
    "        self.anchor_images   = anchor_images\n",
    "        self.positive_images = positive_images\n",
    "        self.negative_images = negative_images\n",
    "        self.data_length     = anchor_images.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment_image(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Augment a single image applying following random transformations:\n",
    "        \n",
    "        Brightness adjustment.\n",
    "        Contrast adjustment.\n",
    "        Flip from the left to the right.\n",
    "        Jpeg quality adjustment.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        image: np.ndarray\n",
    "            Input image to augment.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray: augmented image.\n",
    "        \"\"\"\n",
    "        seed = (42, 42)\n",
    "        image = image / 255\n",
    "        image = tf.image.stateless_random_flip_left_right(image, seed=seed)\n",
    "        image = tf.image.stateless_random_brightness(image, max_delta=0.1, seed=seed)\n",
    "        image = tf.image.stateless_random_contrast(image, lower=0.9, upper=1, seed=seed)\n",
    "        image = tf.image.stateless_random_jpeg_quality(image, min_jpeg_quality=90, max_jpeg_quality=100, seed=seed)\n",
    "        image = tf.image.stateless_random_saturation(image, lower=0.9, upper=1, seed=seed)\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.image.resize(image, IMAGE_SIZE)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    def preprocess(self) -> None:\n",
    "        \"\"\"Preprocessed inputed images converting them into tf.data.Dataset and applying augmentation.\n",
    "        \"\"\"\n",
    "        self.anchor_images   = tf.data.Dataset.from_tensor_slices(self.anchor_images)\n",
    "        self.positive_images = tf.data.Dataset.from_tensor_slices(self.positive_images)\n",
    "        self.negative_images = tf.data.Dataset.from_tensor_slices(self.negative_images)\n",
    "        \n",
    "        self.anchor_images   = self.anchor_images.map(self.augment_image, num_parallel_calls=AUTOTUNE)\n",
    "        self.positive_images = self.positive_images.map(self.augment_image, num_parallel_calls=AUTOTUNE)\n",
    "        self.negative_images = self.negative_images.map(self.augment_image, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    def assemble_images(self) -> tf.data.Dataset:\n",
    "        \"\"\"Creates corresponding concatendated image dataset with zipped anchor and positive, zipped anchor and negative images.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tf.data.Dataset: concatenated image dataset.\n",
    "        \"\"\"\n",
    "        zipped_anchor_positive_images = tf.data.Dataset.zip((\n",
    "            self.anchor_images,\n",
    "            self.positive_images,\n",
    "            tf.data.Dataset.from_tensor_slices(tf.ones(self.data_length))\n",
    "        ))\n",
    "        zipped_anchor_negative_images = tf.data.Dataset.zip((\n",
    "            self.anchor_images,\n",
    "            self.negative_images,\n",
    "            tf.data.Dataset.from_tensor_slices(tf.zeros(self.data_length))\n",
    "        ))\n",
    "        return tf.data.Dataset.concatenate(\n",
    "            zipped_anchor_positive_images,\n",
    "            zipped_anchor_negative_images\n",
    "        )\n",
    "    \n",
    "    def train_test_validation_split(self, test_size: float) -> (tf.data.Dataset, tf.data.Dataset, tf.data.Dataset):\n",
    "        \"\"\"Splits concatenated image dataset on train, test and validation datasets.\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        test_size: float\n",
    "            The fraction of data will be taken from concatenated image dataset for test split.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tf.data.Dataset: train split dataset.\n",
    "        tf.data.Dataset: test split dataset.\n",
    "        \"\"\"\n",
    "        assert test_size < 1, \"Test fraction size must be less than 1!\"\n",
    "        \n",
    "        concatenated_images = self.assemble_images()\n",
    "        new_data_length     = self.data_length * 2\n",
    "        concatenated_images = concatenated_images.shuffle(buffer_size=new_data_length, seed=42)\n",
    "        \n",
    "        train_data = concatenated_images.take(round(new_data_length * (1 - test_size)))\n",
    "        train_data = train_data.batch(BATCH_SIZE)\n",
    "        train_data = train_data.prefetch(BATCH_SIZE // 2)\n",
    "        train_data = train_data.cache()\n",
    "        \n",
    "        test_data  = concatenated_images.skip(round(new_data_length * (1 - test_size)))\n",
    "        test_data  = concatenated_images.take(round(new_data_length * test_size))\n",
    "        test_data  = test_data.batch(BATCH_SIZE)\n",
    "        test_data  = test_data.prefetch(BATCH_SIZE // 2)\n",
    "        test_data  = test_data.cache()\n",
    "        \n",
    "        return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006563663482666016\n",
      "0.006757497787475586\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_preprocessor.augment_image(anchor_images[0])\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4022786617279053\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "data_preprocessor = DataPreprocessor(anchor_images, positive_images, negative_images)\n",
    "start = time.time()\n",
    "data_preprocessor.preprocess()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_preprocessor.train_test_validation_split(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del anchor_images, positive_images, negative_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYA-a0urf3up",
    "tags": []
   },
   "source": [
    "<a name=\"build-it\"></a>\n",
    "#### 3. **Построение модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DistanceL2(Layer):\n",
    "    \"\"\"L2 distance layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DistanceL2, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, real_embedding, deceptive_embedding):\n",
    "        return tf.math.square(real_embedding - deceptive_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "n6POht5ii5_r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneHand(Model):\n",
    "    \"\"\"The anchor-positive or anchor-negative models. Part of the main one.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OneHand, self).__init__(**kwargs)\n",
    "        self.input_        = Input(shape=(*IMAGE_SIZE, 1), name='input')\n",
    "        self.conv2d_1      = Conv2D(filters=64, kernel_size=(10, 10), activation='relu')\n",
    "        self.max_pooling_1 = MaxPool2D(pool_size=(2, 2), padding='same')\n",
    "        self.conv2d_2      = Conv2D(filters=128, kernel_size=(7, 7), activation='relu')\n",
    "        self.max_pooling_2 = MaxPool2D(pool_size=(2, 2), padding='same')\n",
    "        self.conv2d_3      = Conv2D(filters=128, kernel_size=(4, 4), activation='relu')\n",
    "        self.max_pooling_3 = MaxPool2D(pool_size=(2, 2), padding='same')\n",
    "        self.conv2d_4      = Conv2D(filters=256, kernel_size=(4, 4), activation='relu')\n",
    "        self.flatten_      = Flatten()\n",
    "        self.dense_        = Dense(units=4096, activation='sigmoid')\n",
    "    \n",
    "    def call(self, name=None):\n",
    "        x = self.conv2d_1(self.input_)\n",
    "        x = self.max_pooling_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.flatten_(x)\n",
    "        outputs = self.dense_(x)\n",
    "        \n",
    "        return Model(inputs=[self.input_], outputs=[outputs], name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SiameseNN(Model):\n",
    "    \"\"\"Siamese neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SiameseNN, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, name=None):\n",
    "        real_input      = Input(shape=(*IMAGE_SIZE, 1))\n",
    "        deceptive_input = Input(shape=(*IMAGE_SIZE, 1))\n",
    "        \n",
    "        one_hand           = OneHand()('one_hand')\n",
    "        real_one_hand      = one_hand(real_input)\n",
    "        deceptive_one_hand = one_hand(deceptive_input)\n",
    "        \n",
    "        distance_l2 = DistanceL2()\n",
    "        x           = distance_l2(real_one_hand, deceptive_one_hand)\n",
    "        outputs     = Dense(units=1, activation='sigmoid')(x)\n",
    "        \n",
    "        return Model(inputs=[real_input, deceptive_input], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNN()('SiameseModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseModel\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 105, 105, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 105, 105, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " one_hand (Functional)          (None, 4096)         38947648    ['input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " distance_l2_2 (DistanceL2)     (None, 4096)         0           ['one_hand[0][0]',               \n",
      "                                                                  'one_hand[1][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            4097        ['distance_l2_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"teach-it\"></a>\n",
    "#### 4. **Обучение модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch: tf.Tensor, loss_function: tf.keras.losses.Loss=tf.keras.losses.BinaryCrossentropy()) -> float:\n",
    "    \"\"\"The single step of training model using one batch of data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    batch: tf.Tensor\n",
    "        A batch of data to train the model.\n",
    "    loss_function: tf.keras.losses.Loss, default=tf.keras.losses.BinaryCrossentropy()\n",
    "        A loss function to adjust weights of training model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float: calculated loss result.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = batch[:2]\n",
    "        y = batch[2]\n",
    "    \n",
    "        y_pred = model(X, training=True)\n",
    "        loss = loss_function(y, y_pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, model.trainable_variables)\n",
    "    )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchmark(\n",
    "    data: tf.data.Dataset,\n",
    "    epochs: int,\n",
    "    loss_function: tf.keras.losses.Loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    checkpoint: tf.train.Checkpoint | None=None,\n",
    "    silent: bool=False\n",
    ") -> dict:\n",
    "    \"\"\"Full cycle of training the inputed SiameseNN model.\n",
    "    \n",
    "    Attirbutes\n",
    "    ----------\n",
    "    model: tf.keras.Model\n",
    "        The model that will be trained.\n",
    "    data: tf.data.Dataset\n",
    "        The data that will be used to train the the inputed model.\n",
    "    epochs: int\n",
    "        The number of epochs to train the the inputed model.\n",
    "    loss_function: tf.keras.losses.Loss, default=tf.keras.losses.BinaryCrossentropy()\n",
    "        A loss function to adjust weights of training model.\n",
    "    checkpoint: tf.train.Checkpoint, default=None\n",
    "        The checkpoint class to save weights.\n",
    "    silent: bool, default=False\n",
    "        Whether or not to show progress bar.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict: the dict of lists of metrics, like loss, precision and recall.\n",
    "    \"\"\"\n",
    "    history = {'loss': [], 'precision': [], 'recall': []}\n",
    "    progbar = None\n",
    "    \n",
    "    if checkpoint is not None:\n",
    "        checkpoints_directory = pathlib.Path('checkpoints')\n",
    "        checkpoints_prefix = checkpoints_directory / 'ckpt'\n",
    "\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        if not silent:\n",
    "            progbar = tf.keras.utils.Progbar(len(data), verbose=1)\n",
    "        \n",
    "        recall    = Recall()\n",
    "        precision = Precision() \n",
    "        \n",
    "        for i, batch in enumerate(data, start=1):\n",
    "            loss   = train_step(batch, loss_function=loss_function)\n",
    "            y_pred = model(batch[:2], training=False)\n",
    "            \n",
    "            recall.update_state(batch[2], y_pred)\n",
    "            precision.update_state(batch[2], y_pred)\n",
    "            if not silent:\n",
    "                progbar.update(i)\n",
    "        \n",
    "        print(f'loss={loss.numpy()} precision={precision.result().numpy()} recall={recall.result().numpy()}')\n",
    "        history['loss'].append(loss.numpy())\n",
    "        history['precision'].append(precision.result().numpy())\n",
    "        history['recall'].append(recall.result().numpy())\n",
    "        \n",
    "        if checkpoint is not None and epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoints_prefix)\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS        = 50\n",
    "LOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 223ms/step\n",
      "loss=0.6852598786354065 precision=0.75 recall=0.3333333432674408\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "loss=0.4538150131702423 precision=0.8611111044883728 recall=0.3827160596847534\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "loss=0.5500621795654297 precision=0.8309859037399292 recall=0.7283950448036194\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "loss=0.5884055495262146 precision=0.6477272510528564 recall=0.7037037014961243\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 156ms/step\n",
      "loss=0.452488511800766 precision=0.746666669845581 recall=0.6913580298423767\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 162ms/step\n",
      "loss=0.5144887566566467 precision=0.7792207598686218 recall=0.7407407164573669\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 162ms/step\n",
      "loss=0.3705010414123535 precision=0.862500011920929 recall=0.8518518805503845\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 162ms/step\n",
      "loss=0.3507099449634552 precision=0.9367088675498962 recall=0.9135802388191223\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 156ms/step\n",
      "loss=0.23006993532180786 precision=0.9876543283462524 recall=0.9876543283462524\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 158ms/step\n",
      "loss=0.18499356508255005 precision=0.9390243887901306 recall=0.9506173133850098\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.18994708359241486 precision=0.9615384340286255 recall=0.9259259104728699\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 152ms/step\n",
      "loss=0.12324389815330505 precision=0.9624999761581421 recall=0.9506173133850098\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 153ms/step\n",
      "loss=0.11895615607500076 precision=0.9506173133850098 recall=0.9506173133850098\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.10786665230989456 precision=0.9512194991111755 recall=0.9629629850387573\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.07024350017309189 precision=0.9876543283462524 recall=0.9876543283462524\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 157ms/step\n",
      "loss=0.047133468091487885 precision=0.987500011920929 recall=0.9753086566925049\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 152ms/step\n",
      "loss=0.03503521904349327 precision=1.0 recall=0.9876543283462524\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 162ms/step\n",
      "loss=0.02751886658370495 precision=1.0 recall=0.9876543283462524\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 154ms/step\n",
      "loss=0.02459775283932686 precision=1.0 recall=1.0\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 156ms/step\n",
      "loss=0.023129498586058617 precision=1.0 recall=1.0\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 153ms/step\n",
      "loss=0.02080451138317585 precision=1.0 recall=1.0\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 161ms/step\n",
      "loss=0.018170678988099098 precision=1.0 recall=1.0\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 158ms/step\n",
      "loss=0.01634855754673481 precision=1.0 recall=1.0\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 161ms/step\n",
      "loss=0.014898709021508694 precision=1.0 recall=1.0\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 157ms/step\n",
      "loss=0.013756760396063328 precision=1.0 recall=1.0\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "loss=0.01163849513977766 precision=1.0 recall=1.0\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "loss=0.011324369348585606 precision=1.0 recall=1.0\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 158ms/step\n",
      "loss=0.012299650348722935 precision=1.0 recall=1.0\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 157ms/step\n",
      "loss=0.011883753351867199 precision=1.0 recall=1.0\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 164ms/step\n",
      "loss=0.010511660017073154 precision=1.0 recall=1.0\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 155ms/step\n",
      "loss=0.009467280469834805 precision=1.0 recall=1.0\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.008934191428124905 precision=1.0 recall=1.0\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.008664802648127079 precision=1.0 recall=1.0\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 153ms/step\n",
      "loss=0.008535978384315968 precision=1.0 recall=1.0\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.008444798178970814 precision=1.0 recall=1.0\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.008281207643449306 precision=1.0 recall=1.0\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 161ms/step\n",
      "loss=0.008023155853152275 precision=1.0 recall=1.0\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 157ms/step\n",
      "loss=0.007726151961833239 precision=1.0 recall=1.0\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 160ms/step\n",
      "loss=0.007447983603924513 precision=1.0 recall=1.0\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 160ms/step\n",
      "loss=0.007213002070784569 precision=1.0 recall=1.0\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.0070185791701078415 precision=1.0 recall=1.0\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 156ms/step\n",
      "loss=0.006850372534245253 precision=1.0 recall=1.0\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.006692768540233374 precision=1.0 recall=1.0\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 150ms/step\n",
      "loss=0.006535467691719532 precision=1.0 recall=1.0\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 160ms/step\n",
      "loss=0.006375635042786598 precision=1.0 recall=1.0\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 151ms/step\n",
      "loss=0.006215797271579504 precision=1.0 recall=1.0\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 154ms/step\n",
      "loss=0.006060166750103235 precision=1.0 recall=1.0\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 161ms/step\n",
      "loss=0.005911878775805235 precision=1.0 recall=1.0\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 157ms/step\n",
      "loss=0.0057719494216144085 precision=1.0 recall=1.0\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 159ms/step\n",
      "loss=0.00563967926427722 precision=1.0 recall=1.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(5e-2)\n",
    "i         = 1\n",
    "\n",
    "model      = SiameseNN()(f'SiameseModel_{i}')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "history = benchmark(train_data, EPOCHS, loss_function=LOSS_FUNCTION, checkpoint=checkpoint)\n",
    "\n",
    "del i, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQSIZFOEf3rk",
    "tags": []
   },
   "source": [
    "<a name=\"validate\"></a>\n",
    "#### 5. **Валидация модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history(history: dict) -> None:\n",
    "    \"\"\"Plots model's history of its losses and metrics.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    history: dict\n",
    "        Dictionary of metrics used while training to evaluate its progress.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.set_title('Model history')\n",
    "    \n",
    "    for metric in history.keys():\n",
    "        ax.plot(range(1, len(history[metric])+1), history[metric], c=np.random.rand(3), label=metric)\n",
    "\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric value')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data: tf.data.Dataset, model) -> None:\n",
    "    \"\"\"Evaluates model with a specified test data using following metrics:\n",
    "    1) Confusion matrix\n",
    "    2) Precision\n",
    "    3) Recall\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    recall                       = Recall()\n",
    "    precision                    = Precision()\n",
    "    confusion_matrix_true_buffer = []\n",
    "    confusion_matrix_pred_buffer = []\n",
    "\n",
    "    for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "        y_pred = model.predict([test_input, test_val], verbose=0)\n",
    "        y_pred = np.array([1 if prediction > 0.5 else 0 for prediction in y_pred]).astype('float32')\n",
    "        recall.update_state(y_true, y_pred)\n",
    "        precision.update_state(y_true, y_pred)\n",
    "        confusion_matrix_true_buffer.extend(list(y_true))\n",
    "        confusion_matrix_pred_buffer.extend(list(y_pred))\n",
    "\n",
    "    print(f'Recall: {recall.result().numpy()}, Precision: {precision.result().numpy()}')\n",
    "    print(f'Confusion matrix:\\n{tf.math.confusion_matrix(confusion_matrix_true_buffer, confusion_matrix_pred_buffer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)\n",
    "del history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 1.0, Precision: 1.0\n",
      "Confusion matrix:\n",
      "[[23  0]\n",
      " [ 0 27]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(test_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2WM55aGf3o6",
    "tags": []
   },
   "source": [
    "<a name=\"upload\"></a>\n",
    "#### 6. **Выгрузка модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copy_files_to_app(update=True):\n",
    "    \"\"\"Copy trained model and positive images to the app storage ('app/src/data/registered').\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    update: bool, default=True\n",
    "        Whether or not to update destination path.\n",
    "    \"\"\"\n",
    "    app_source_path = pathlib.Path('app/src')\n",
    "    cascades_path   = pathlib.Path('cascades')\n",
    "    model_path      = pathlib.Path('fr_model.tflite')\n",
    "    data_path       = pathlib.Path('data')\n",
    "    \n",
    "    \n",
    "    if update:\n",
    "        try:\n",
    "            shutil.rmtree(app_source_path / data_path)\n",
    "            shutil.rmtree(app_source_path / cascades_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            \n",
    "    shutil.copytree(data_path, app_source_path / data_path)\n",
    "    shutil.copytree(cascades_path, app_source_path / cascades_path)\n",
    "    shutil.copy(model_path, app_source_path / model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "2FzxGh69i8F7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fr_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fr_model/assets\n",
      "2022-12-07 07:36:24.570894: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-12-07 07:36:24.570922: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "model.save('fr_model')\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('fr_model')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('fr_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files_to_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"real-time\"></a>\n",
    "#### 7. **Проверка на реальном примере**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verify(input_image: np.ndarray | tf.Tensor, detection_threshold: float, verification_threshold: float) -> (list, int):\n",
    "    \"\"\"Verify input_image similarity with the 'data/registered/*' images.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    input_image: np.ndarray | tf.Tensor\n",
    "        The snap made to compare with 'data/registered/*' images.\n",
    "    detection_threshold: float\n",
    "        The threshold at which the result is acceptable to be varified for a single image.\n",
    "    verification_threshold: float\n",
    "        The threshold at which the result is acceptable to be varified for the sum of fractions of all images.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list: the results of verifications for each image.\n",
    "    int: 0 or 1. Whether the input_image is verified or not.\n",
    "    \"\"\"\n",
    "    outputs     = []\n",
    "    input_image = DataPreprocessor.augment_image(input_image)\n",
    "    \n",
    "    for positive_image in positive_images:\n",
    "        positive_image = DataPreprocessor.augment_image(positive_image)\n",
    "        output         = model.predict(list(np.expand_dims([input_image, positive_image], axis=1)), verbose=0)\n",
    "        outputs.append(output)\n",
    "    \n",
    "    detection    = np.sum(np.array(outputs) > detection_threshold)\n",
    "    verification = detection / len(positive_images)\n",
    "    verification = verification > verification_threshold\n",
    "    \n",
    "    return outputs, verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader()\n",
    "positive_images, _, _ = data_loader.load('positive')\n",
    "model = tf.keras.models.load_model('fr_model', custom_objects={'DistanceL2': DistanceL2, 'OneHand': OneHand})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(cv2.CAP_ANY)\n",
    "\n",
    "while cam.isOpened():\n",
    "    _, frame = cam.read()\n",
    "    frame = np.flip(frame, axis=1)\n",
    "    \n",
    "    cv2.imshow('Verification', frame)\n",
    "    x1, y1, x2, y2 = get_faces(frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('v'):\n",
    "        if x1 and y1 and x2 and y2:\n",
    "            outputs, verification = verify(frame[y1:y2, x1:x2], 0.5, 0.5)\n",
    "            print(verification)\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOAQxzyv3Es9V5eKVWzENVX",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
